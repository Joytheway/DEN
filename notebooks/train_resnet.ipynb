{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet152\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import NyuV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/nyu_v2/'\n",
    "batch_size = 4\n",
    "# img_size = (224, 224)\n",
    "depth_size = (25, 32)\n",
    "# max_img_val = 255.0\n",
    "# max_depth_val = 9.9955\n",
    "nepochs = 1\n",
    "seed = 2\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(NyuV2(os.path.join(data_path, 'train')),\n",
    "                               batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(NyuV2(os.path.join(data_path, 'test')),\n",
    "                              batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152(pretrained=True)\n",
    "model.fc = nn.Linear(2048, depth_size[0] * depth_size[1])\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        depth_maps = model(data)\n",
    "        loss = F.mse_loss(depth_maps, labels, reduction='sum')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch * len(data), len(train_loader.dataset),\n",
    "                100. * batch / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    \n",
    "    return train_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 [0/1100 (0%)]\tLoss: 137.698898\n",
      "Train epoch: 1 [400/1100 (36%)]\tLoss: 6.432196\n",
      "Train epoch: 1 [800/1100 (73%)]\tLoss: 6.792730\n",
      "====> Epoch: 1 time: 2.0m Average loss: 13.4252 RMSE: 3.6640\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nepochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    avg_train_loss = train(epoch)\n",
    "    print('====> Epoch: {} time: {:.1f}m Average loss: {:.4f} RMSE: {:.4f}'.format(\n",
    "        epoch, (time.time() - epoch_start_time) / 60, avg_train_loss, avg_train_loss**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152(pretrained=True)\n",
    "model.fc = nn.Linear(2048, depth_size[0] * depth_size[1])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params': base_params}], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 [0/1100 (0%)]\tLoss: 167.228500\n",
      "Train epoch: 1 [400/1100 (36%)]\tLoss: 30.466412\n",
      "Train epoch: 1 [800/1100 (73%)]\tLoss: 45.088535\n",
      "====> Epoch: 1 time: 1.9m Average loss: 46.6467 RMSE: 6.8298\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, nepochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    avg_train_loss = train(epoch)\n",
    "    print('====> Epoch: {} time: {:.1f}m Average loss: {:.4f} RMSE: {:.4f}'.format(\n",
    "        epoch, (time.time() - epoch_start_time) / 60, avg_train_loss, avg_train_loss**0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
