{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "f4227175-24e6-441e-aa4d-79ba6500b901"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  0.4.1\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet152\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from dataset import NyuV2\n",
    "from modeling import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "bbf3b54b-68ee-479a-8f28-3c31567b2ddb"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/nyu_v2/'\n",
    "batch_size = 16\n",
    "# img_size = (224, 224)\n",
    "depth_size = (25, 32)\n",
    "# max_img_val = 255.0\n",
    "# max_depth_val = 9.9955\n",
    "n_epochs = 3\n",
    "seed = 2\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "55065120-b2fe-4a79-9d9b-543af8a6186a"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': data.DataLoader(NyuV2(os.path.join(data_path, 'train')),\n",
    "                               batch_size=batch_size, shuffle=True),\n",
    "    'val': data.DataLoader(NyuV2(os.path.join(data_path, 'test')),\n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ft_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.fc = nn.Linear(2048, depth_size[0] * depth_size[1])\n",
    "#     params_to_update = model.parameters()\n",
    "    \n",
    "    print(\"Params to learn:\")\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "            \n",
    "    return model, params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "1b2c8fd4-1c23-4ef1-8ec4-089052736d41"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "model = resnet152(pretrained=True)\n",
    "model, params_to_update = init_ft_model(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params_to_update, lr=1e-4)\n",
    "criterion = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   Loss: 38.3439 RMSE: 6.1922\n",
      "Validation: Loss: 33.0862 RMSE: 5.7521\n",
      "Epoch complete in 0m 48s\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "Training:   Loss: 23.4274 RMSE: 4.8402\n",
      "Validation: Loss: 25.5786 RMSE: 5.0575\n",
      "Epoch complete in 0m 47s\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "Training:   Loss: 18.9105 RMSE: 4.3486\n",
      "Validation: Loss: 22.5182 RMSE: 4.7453\n",
      "Epoch complete in 0m 47s\n",
      "\n",
      "Training complete in 2m 23s\n",
      "Best val loss: 22.518163\n"
     ]
    }
   ],
   "source": [
    "model, train_loss_history, val_loss_history = train_model(model, dataloaders,\n",
    "                                                          criterion, optimizer,\n",
    "                                                          n_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
